{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIo9jeVDfmPt",
        "outputId": "cbba8f21-9c03-42d0-a14c-1809a8deeea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: captum in /usr/local/lib/python3.12/dist-packages (0.8.0)\n",
            "Requirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.12/dist-packages (2.3.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.85)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from captum) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from captum) (25.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2025.11.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install captum torchtext==0.18.0 torch==2.3.1 datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sEWfBrzqkgnj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Data and Dictionary\n",
        "dataset = load_dataset(\"imdb\")\n",
        "train_data = dataset['train'].shuffle(seed=42) # Only 1000 data for speed up but now wole dataset\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    return text.split()\n",
        "\n",
        "vocab = build_vocab_from_iterator([clean_text(x['text']) for x in train_data], min_freq=2, specials=[\"<pad>\", \"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "# Basic LSTM Model\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        # forward function must be simpler for Captum\n",
        "        embedded = self.embedding(text)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        return self.fc(hidden[-1])\n",
        "\n",
        "model = LSTMClassifier(len(vocab), 100, 64, 2).to(device) # 2 Outputs: Negative, Pozitive\n",
        "\n",
        "# Fast Training\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for i, item in enumerate(train_data):\n",
        "    # if i > 100: break # 100 steps is enough\n",
        "    text = torch.tensor([vocab[t] for t in clean_text(item['text'])]).to(device).unsqueeze(0)\n",
        "    label = torch.tensor([item['label']]).to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(text)\n",
        "    loss = criterion(preds, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovsRLd6tkrBP",
        "outputId": "d2c090a6-4d9d-4296-fd5a-7fdabbcbc52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Word Scores ---\n",
            "(Pozitive scores support decision, negative ones hinder)\n",
            "\n",
            "this            | +0.0148 | \u001b[92m (POSITIVE)\u001b[0m\n",
            "movie           | -0.1885 | \u001b[91m█████████ (NEGATIVE)\u001b[0m\n",
            "was             | +0.6033 | \u001b[92m██████████████████████████████ (POSITIVE)\u001b[0m\n",
            "absolutely      | -0.4452 | \u001b[91m██████████████████████ (NEGATIVE)\u001b[0m\n",
            "wonderful       | +0.0230 | \u001b[92m█ (POSITIVE)\u001b[0m\n",
            "and             | -0.1221 | \u001b[91m██████ (NEGATIVE)\u001b[0m\n",
            "brilliant       | +0.6217 | \u001b[92m███████████████████████████████ (POSITIVE)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from captum.attr import IntegratedGradients, LayerIntegratedGradients\n",
        "from captum.attr import visualization as viz\n",
        "\n",
        "model.train()\n",
        "\n",
        "# Example sentence to analyze\n",
        "ornek_yorum = \"this movie was absolutely wonderful and brilliant\"\n",
        "label = 1 # 1: Pozitive\n",
        "\n",
        "# Prepare sentence for model\n",
        "tokens = clean_text(ornek_yorum)\n",
        "input_indices = torch.tensor([vocab[t] for t in tokens]).to(device).unsqueeze(0)\n",
        "\n",
        "# Define Integrated Gradients\n",
        "lig = LayerIntegratedGradients(model, model.embedding)\n",
        "\n",
        "# Calculate (Target: label=1 meaning Pozitive)\n",
        "attributions, delta = lig.attribute(input_indices, target=label, n_steps=50, return_convergence_delta=True)\n",
        "\n",
        "\n",
        "# Visualization\n",
        "def visualize_attributions(attributions, tokens):\n",
        "    attributions = attributions.sum(dim=2).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    attributions = attributions.cpu().detach().numpy()\n",
        "\n",
        "    print(\"\\n--- Word Scores ---\")\n",
        "    print(\"(Pozitive scores support decision, negative ones hinder)\\n\")\n",
        "\n",
        "    for token, score in zip(tokens, attributions):\n",
        "        # A basic bar for visualization\n",
        "        bar_len = int(abs(score) * 50)\n",
        "        bar = \"█\" * bar_len\n",
        "        if score > 0:\n",
        "            print(f\"{token:15} | {score:+.4f} | \\033[92m{bar} (POSITIVE)\\033[0m\") # Green\n",
        "        else:\n",
        "            print(f\"{token:15} | {score:+.4f} | \\033[91m{bar} (NEGATIVE)\\033[0m\") # Red\n",
        "\n",
        "visualize_attributions(attributions, tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUf53Ur9lK_W",
        "outputId": "431c341c-9db7-49d0-ee43-8dddd65603ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: 'the movie was not bad actually'\n",
            "Prediction: Pozitive\n",
            "Confidence: 0.5415\n",
            "Entropy: 0.6897 (If it is high model is indecisive)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def analyze_uncertainty(text):\n",
        "    tokens = clean_text(text)\n",
        "    input_indices = torch.tensor([vocab[t] for t in tokens]).to(device).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_indices)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        # Entropi Calculation: -sum(p * log(p))\n",
        "        entropy = -torch.sum(probs * torch.log(probs + 1e-9), dim=1).item()\n",
        "\n",
        "        pred_class = torch.argmax(probs, dim=1).item()\n",
        "        confidence = probs[0][pred_class].item()\n",
        "\n",
        "    return pred_class, confidence, entropy\n",
        "\n",
        "# Error scenario (an example sentence)\n",
        "# \"Movie wasn't bad\" -> It actually means good but since it contains the word \"bad\" model could suprised\n",
        "diff_sentence = \"the movie was not bad actually\"\n",
        "\n",
        "pred, conf, entropy = analyze_uncertainty(diff_sentence)\n",
        "\n",
        "print(f\"Sentence: '{diff_sentence}'\")\n",
        "print(f\"Prediction: {'Pozitive' if pred == 1 else 'Negative'}\")\n",
        "print(f\"Confidence: {conf:.4f}\")\n",
        "print(f\"Entropy: {entropy:.4f} (If it is high model is indecisive)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}